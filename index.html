<!doctype html>
<html lang="en">
  <head>
    <!-- Legacya -->

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="./assets/dist/css/bootstrap.css" rel="stylesheet">
    <!-- Bootstrap CSS -->
    <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous"> -->
    <link rel="stylesheet" href="./jjpark_files/font-awesome.min.css"> <!--icon library-->
    <script src="https://kit.fontawesome.com/533c2d0dc3.js" crossorigin="anonymous"></script>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;500;600;700&display=swap" rel="stylesheet">   <!--web font-->
    <link rel="stylesheet" href="./jjpark_files/style.css">
    <link rel="stylesheet" href="./jjpark_files/academicons.min.css">
    <link rel="shortcut icon" href="./jjpark_files/um.png" type="image/vnd.microsoft.icon" />
    <script src="./jjpark_files/jquery.min.js"></script>
    <script language="JavaScript">
    function ShowHide(divId) {
      $(divId).slideToggle(200);
    }
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="./jjpark_files/academicons.min.css">

<!--             <a href="https://arxiv.org/pdf/2001.04642.pdf" target="_blank"> <video style="width:100%; max-width:320px; margin:10px align:center" autoplay muted loop controls>
  <source src="./jjpark_files/test.mp4" type="video/mp4">
</video> </a>
 -->
    <title>JJ Park</title>
  </head>
  <body>
    <!-- jj info -->
    <div class="container">
      <div class="row">
        <div class="col-sm-6 col-lg-4">
          <img src="./jjpark_files/jj_2023.JPG" class="img-responsive img-rounded" style="width:100%; border-radius: 50%">
        </div>
        <div class="col-sm-6 col-lg-8">
          <h1>JJ (Jeong Joon) Park</h1>
          <h3><i class="far fa-envelope iconbtn"></i>jjparkcv (at) umich (dot) edu</h3>
          <p> <b>I'm an assisant professor at the University of Michigan CSE (Office: BBB2717). </b><br>  I'm broadly interested in computer vision, graphics, and artificial intelligence. My current research focus is on 3D/4D reconstruction and generative modeling and their applications to robotics, medical imaging, and scientific problems. <br/>
           <br>
          <b>I'm looking for students and postdoc applicants!</b><br/> Please refer to the note below for details. I encourage interested students to apply to the UMichigan CSE PhD program and mention my name in the application. 

        </p>
          <details>
    <summary>Prospective Students and Postdocs</summary>
    I'm mainly looking for PhD and postdoc applicants who satisfy one of the items listed below:
      <ul>
  <!-- <li>Experience with 3D vision (including medical imaging) and generative models</li> -->
  <li>Physics background with deep learning experience</li>
  <li>Robot learning background</li>
  <li>3D/4D vision background (including medical imaging)</li>
  <li>Computer graphics and simulation background</li>
  <li>Machine learning background</li>
  <li>Computational Neuroscience background with deep learning experience</li>
</ul>   
Postdocs: I am also looking for postdocs through (1) <a href="https://micde.umich.edu/research-scholars-program/">MICDE Research Scholars</a> and (2) <a href="https://midas.umich.edu/ai-in-science-2/apply-2/"> Schmidt AI in Science programs </a>.
<br><br>
For UMichigan undergrads and masters' students please send an email with resume -- note that I expect a significant time commitment (>15hrs/week).
Unfortunately, I will not be able to respond to all emails.

</details>
<details>
    <summary>Current Students</summary>
    <a href="https://liamjwang.github.io/">Liam Wang</a> (2024-, NSF GRFP Fellow)<br>
    <a href="https://zichenwang01.github.io/">Zichen Wang</a> (2024- )<br>
    <a href="https://maopaom.github.io/">Lixuan Chen</a> (2024-, Co-advised with Liyue Shen)<br>
    <a href="https://caoang327.github.io/"> Ang Cao</a> (2020-, co-advised with Justin Johnson)
</details>

<details>
    <summary>Teaching</summary>
    <a href="https://eecs442.github.io/">Computer Vision (EECS 442), Winter 2024</a><br>
    <a href="https://um-graphics.github.io/">Computer Graphics and Generative Models, Fall 2024</a><br>
</details>


          <!-- I am fortunate to collaborate with my labmates at Stanford and UW, and mentors I met during my internships at Apple, Facebook, and Adobe. I was supported by <a href="https://machinelearning.apple.com/updates/introducing-apple-scholars-aiml"> Apple Fellowship </a> during my PhD studies. Prior to PhD, I received B.S. from Caltech, working at Pietro Perona's vision lab.</p> -->
          <!-- <div style="text-align:center; vertical-align: left ;margin-top: 0px; margin-bottom: 20px;"> -->
            <a href="./jjpark_files/JJPARK_CV.pdf"><button class="largebtn"><i class="far fa-file-alt iconbtn"></i>CV</button></a>
            <a href="https://scholar.google.com/citations?user=aD5pXLoAAAAJ&hl=en&oi=sra"><button class="largebtn"><i class="fas fa-graduation-cap iconbtn"></i>SCHOLAR</button> </a>
            <a href="https://twitter.com/jjpark3d"><button class="largebtn"><i class="fab fa-twitter iconbtn"></i>TWITTER</button> </a>
            <a href="https://www.youtube.com/channel/UCQw0PoLCEOu6mGgwiryu4tg"><button class="largebtn"><i class="fab fa-youtube iconbtn"></i>YOUTUBE</button> </a>
          <!-- </div> -->
        </div>
      </div>
      <hr>
    </div>
    <h2 align ="center">Publications</h2>

<!-- first publication -->




        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4 d-flex align-items-center justify-content-center">
      <img src="./jjpark_files/sirdiff.gif" class="card-img" style="width:100%; max-width:350px;">
    </div>
      <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title"><br>SIR-DIFF: Sparse Image Sets Restoration with <br>Multi-View Diffusion Model</h5>
            <p class="card-text author">Yucheng Mao, Boyang Wang, Nilesh Kulkarni, Jeong Joon Park

 <br><em>CVPR 2025</em><br>
</p> 
              <a href="https://arxiv.org/pdf/2503.14463" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://myc634.github.io/sirdiff/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>


        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/thisandthat.gif" class="card-img" style="width:100%; max-width:350px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">This&That: Language-Gesture Controlled Video Generation for Robot Planning</h5>
            <p class="card-text author">Boyang Wang, Nikhil Sridhar, Chao Feng, Mark Van der Merwe, Adam Fishman, Nima Fazeli, Jeong Joon Park

 <br><em>ICRA 2025</em><br>
</p> 
              <a href="https://arxiv.org/abs/2407.05530" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://cfeng16.github.io/this-and-that/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>


        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
<div class="col-md-4 d-flex align-items-center justify-content-center">
  <img src="./jjpark_files/liftgs.gif" class="card-img" style="width:100%; max-width:350px;">
</div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title"><br>3D Visual Language Grounding via <br>Render-Supervised Distillation from 2D VLMs
</h5>
            <p class="card-text author">Ang Cao, Sergio Arnaud, Oleksandr Maksymets, ..., <br> Justin Johnson, Jeong Joon Park, Alexander Sax



 <br><em>ICML 2025</em><br>
</p> 
              <a href="https://arxiv.org/pdf/2503.14463" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://myc634.github.io/sirdiff/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              </p>
          </div>
        </div>
      </div>
    </div>


        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/cocoon2.png" class="card-img" style="width:100%; max-width:350px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">Cocoon: Robust Multi-Modal Perception With Uncertinaty-Aware Sensor Fusion</h5>
            <p class="card-text author">Minkyoung Cho, Yulong Cao, Jiachen Sun, Qingzhao Zhang, Marco Pavone, Jeong Joon Park, Heng Yang, Zhuoqing Mao
 <br><em>ICLR 2025</em><br>
</p> 
              <a href="https://arxiv.org/pdf/2410.12592" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://minkyoungcho.github.io/cocoon//" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>


        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/ns_inverse.gif" class="card-img" style="width:110%; max-width:360px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">DiffusionPDE: Generative PDE-Solving Under Partial Observation</h5>
            <p class="card-text author">Jiahe Huang, Guandao Yang, Zichen Wang, Jeong Joon Park
 <br><em>NeurIPS 2024</em><br>
</p> 
              <a href="https://arxiv.org/abs/2406.17763" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://jhhuang.tech/Diffusion-PDE/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>



        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/tc4d.gif" class="card-img" style="width:110%; max-width:350px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">TC4D: Trajectory-Conditioned Text-to-4D Generation</h5>
            <p class="card-text author">S. Bahmani, X. Liu, Y. Wang, I. Skorokhodov, V. Rong, Z. Liu, X. Liu,
<br>JJ Park, S. Tulyakov, G. Wetzstein, A. Tagliasacchi, D Lindell 
 <br><em>ECCV 2024</em><br>
</p> 
              <a href="https://arxiv.org/abs/2403.17920" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://sherwinbahmani.github.io/tc4d/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>

        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/4dfy.gif" class="card-img" style="width:110%; max-width:350px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling</h5>
            <p class="card-text author">S. Bahmani, I. Skorokhodov, V. Rong, G. Wetzstein, L. Guibas, P. Wonka, S. Tulyakov, J.J. Park, A. Tagliasacchi, D.B. Lindell 
 <br><em>CVPR 2024</em><br>
</p> 
              <a href="https://arxiv.org/pdf/2311.17984.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://sherwinbahmani.github.io/4dfy/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>



        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/far_thumbnail.png" class="card-img" style="width:110%; max-width:350px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title"> FAR: Flexible, Accurate and Robust 6DoF Relative Camera Pose Estimation</h5>
            <p class="card-text author">Chris Rockwell, Nilesh Kulkarni, Linyi Jin, <br> Jeong Joon Park, Justin Johnson, David F. Fouhey 
 <br><em>CVPR 2024 (Highlight)</em><br>
</p> 
              <a href="https://arxiv.org/abs/2403.03221" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://crockwell.github.io/far" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>


    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/curve.png" class="card-img" style="width:110%; max-width:340px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">CurveCloudNet: Processing Point Clouds with <br>1D Structure</h5>
            <p class="card-text author"> C. Stearns, D. Rempe, A. Fu, J. Liu, S. Mascha, JJ Park, D. Paschalidou, L. Guibas <br><em>CVPR 2024</em><br>
            <details>
    <summary><font size="4rem">Summary</font></summary>
    <font size="4rem"> We introduce a new point cloud processing scheme which takes advantage of the curve-like structure inherent to modern depth sensors. While existing backbones discard the rich 1D traversal patterns, CurveCloudNet parameterizes the point cloud as a collection of polylines (a "curve cloud‚Äù), establishing a local surface-aware ordering on the points.</font>
</details></p>
              <a href="https://arxiv.org/pdf/2303.12050.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>

              <br>
              </p>
          </div>
        </div>
      </div>
    </div>
        <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><video autoplay muted loop src="./jjpark_files/diffusion3d.mp4" class="card-img" style="width:100%; max-width:320px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">GeNVS: Generative Novel View Synthesis with <br>3D-Aware Diffusion Models</h5>
            <p class="card-text author">E. Chan*, K Nagano*, M Chan*, A. Bergman*, JJ Park*, <br>A. Levy, M. Aittala, S. Mello, T. Karras, G. Wetzstein
 <br><em>ICCV 2023 (Oral)</em><br>
 <details>
    <summary><font size="4rem">Summary</font></summary>
    <font size="4rem">We present a diffusion model for 3D-aware generative novel view synthesis from as few as a single input image. Our model samples from the distribution of possible renderings consistent with the input and is capable of rendering plausible novel views of unbounded regions.</font>
</details>
</p> 
              <a href="https://arxiv.org/pdf/2304.02602.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://nvlabs.github.io/genvs/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>


    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><img src="./jjpark_files/cc3d.png" class="card-img" style="width:80%; max-width:320px; margin:10px align:center">
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">CC3D: Layout-Conditioned Generation of Compositional 3D Scenes</h5>
            <p class="card-text author">Sherwin Bahmani*,
Jeong Joon Park*,
Despoina Paschalidou,
Xingguang Yan,
Gordon Wetzstein,
Leonidas Guibas,
Andrea Tagliasacchi  <br><em>ICCV 2023</em><br>
 <details>
    <summary><font size="4rem">Summary</font></summary>
    <font size="4rem"> We introduce a conditional generative model that synthesizes complex 3D scenes conditioned on 2D semantic scene layouts. Different from most
existing 3D GANs that operate on aligned
single objects, we focus on generating complex 3D scenes
with multiple objects, by modeling the compositional nature
of 3D scenes.</font>
</details>
</p>
              <a href="https://arxiv.org/pdf/2303.12074.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
                            <a href="https://sherwinbahmani.github.io/cc3d/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br>
              </p>
          </div>
        </div>
      </div>
    </div>




    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><a href="https://arxiv.org/pdf/2301.09629.pdf" target="_blank"><img src="./jjpark_files/LEGO-Net.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">LEGO-Net: Learning Regular Rearrangements <br>of Objects in Rooms</h5>
            <p class="card-text author">Qiuhong Anna Wei, Sijie Ding*, Jeong Joon Park*, Rahul Sajnani, Adrien Poulenard, Srinath Sridhar, Leonidas Guibas
 <br><em>CVPR 2023</em><br></p>
              <a href="https://arxiv.org/pdf/2301.09629.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://ivl.cs.brown.edu/research/lego-net.html" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>


    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><a href="https://arxiv.org/pdf/2211.17260.pdf" target="_blank"><img src="./jjpark_files/singraf.gif" class="card-img" style="width:80%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">SinGRAF: Learning a 3D Generative Radiance Field <br> for a Single Scene</h5>
            <p class="card-text author">Minjung Son*, Jeong Joon Park*, Leonidas Guibas, Gordon Wetzstein <br><em>CVPR 2023</em><br></p>
              <a href="https://arxiv.org/pdf/2211.17260.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="http://www.computationalimaging.org/publications/singraf/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>

    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><a href="https://arxiv.org/pdf/2212.04096.pdf" target="_blank"><img src="./jjpark_files/ALTO.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">ALTO: Alternating Latent Topologies <br>for Implicit 3D Reconstruction</h5>
            <p class="card-text author">Zhen Wang*, Shijie Zhou*, Jeong Joon Park, Despoina Paschalidou, Suya You, Gordon Wetzstein, Leonidas Guibas, Achuta Kadambi
 <br><em>CVPR 2023</em><br></p>
              <a href="https://arxiv.org/pdf/2212.04096.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="http://visual.ee.ucla.edu/alto.htm/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>

    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <a href="https://arxiv.org/pdf/2303.09554.pdf" target="_blank"><img src="./jjpark_files/part-aware.gif" class="card-img" style="width:90%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">Generating Part-Aware Editable 3D Shapes <br>without 3D Supervision</h5>
            <p class="card-text author">Konstantinos Tertikas, Despoina Paschalidou, Boxiao Pan, Jeong Joon Park, Mikaela Angelina Uy, Ioannis Emiris, Yannis Avrithis, Leonidas Guibas
 <br><em>CVPR 2023</em><br></p>
              <a href="https://arxiv.org/pdf/2303.09554.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://ktertikas.github.io/part_nerf" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>



    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
          <br><a href="https://arxiv.org/pdf/2206.14797.pdf" target="_blank"><img src="./jjpark_files/4dgan.gif" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">3D-Aware Video Generation</h5>
            <p class="card-text author">S. Bahmani, J. J. Park, D. Paschalidou, H. Tang, <br> G. Wetzstein, L. Guibas, L. V. Gool, R. Timofte <br><em>Transactions on Machine Learning Research (TMLR) 2023</em><br></p>
              <a href="https://arxiv.org/pdf/2206.14797.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://sherwinbahmani.github.io/3dvidgen/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>

    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <a href="https://arxiv.org/pdf/2112.11427.pdf" target="_blank"><img src="./jjpark_files/stylesdf.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation</h5>
            <p class="card-text author">R. Or-El, X. Luo, M. Shan, E. Shechtman, J. J. Park, I. Kemelmacher-Shlizerman <br><em>CVPR 2022 (Oral)</em><br></p>
              <a href="https://arxiv.org/pdf/2112.11427.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://stylesdf.github.io/" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>

<!-- first publication -->
    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <a href="https://arxiv.org/pdf/2112.04645.pdf" target="_blank"><img src="./jjpark_files/cvpr2022lindell.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">BACON: Band-limited Coordinate Networks for Multiscale Scene Representation</h5>
            <p class="card-text author">David Lindell, Dave Van Veen, Jeong Joon Park, and Gordon Wetzstein <br><em>CVPR 2022 (Oral)</em><br></p>
              <a href="https://arxiv.org/pdf/2112.04645.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://davidlindell.com/publications/bacon" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Website</button></a>
              <br><br>
              </p>
          </div>
        </div>
      </div>
    </div>


<!-- first publication -->
    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <a href="https://arxiv.org/pdf/2001.04642.pdf" target="_blank"><img src="./jjpark_files/chips.gif" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">Seeing the World in a Bag of Chips</h5>
            <p class="card-text author">Jeong Joon Park, Aleksander Holynski, Steve Seitz<br><em>CVPR 2020 (Oral)</em><br></p>
              <a href="https://arxiv.org/pdf/2001.04642.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://youtu.be/7m8EKYCcHys" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>1min-Summary</button></a>
              <a href="https://youtu.be/earouS3eyn0" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Oral-Talk</button></a>
              <a href="https://youtu.be/9t_Rx6n1HGA" target="new"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Video</button></a>
              <br><br>
              <a href="https://www.wired.com/story/how-to-see-the-worlds-reflection-from-a-bag-of-chips/" target="_blank" class="press"><i class="far fa-newspaper iconbtn"></i>WIRED</a>
              <a href="https://www.scientificamerican.com/article/a-shiny-snack-bags-reflections-can-reconstruct-the-room-around-it/" target="_blank"><i class="far fa-newspaper iconbtn"></i>Scientific American</a><br>
              </p>
          </div>
        </div>
      </div>
    </div>


<!-- second publication -->
    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <br><a href="https://arxiv.org/pdf/1901.05103.pdf" target="_blank"><img src="./jjpark_files/deepsdf.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation</h5>
            <p class="card-text author">Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, Steven Lovegrove<br><em>CVPR 2019 (Oral, <b>Best Paper Award Finalist</b>)</em><br></p>
              <a href="https://arxiv.org/pdf/1901.05103.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://youtu.be/0lLnHe0xbZE?t=1404" target="_blank"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Oral-Talk</button></a>
              <a href="https://youtu.be/LILRJzMQw5o" target="new"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Video</button></a>
              <a href="https://github.com/facebookresearch/DeepSDF" target="_blank"><button class="smallbtn"><i class="fas fa-code iconbtn"></i>Code</button></a>
            </p>
          </div>
        </div>
      </div>
    </div>


<!-- third publication -->
    <div class="card mb-3" style="max-width: 1080px;">
      <div class="row no-gutters">
        <div class="col-md-4">
            <a href="https://arxiv.org/pdf/1809.02057.pdf" target="_blank"><img src="./jjpark_files/slfusion.png" class="card-img" style="width:100%; max-width:320px; margin:10px align:center"></a>
        </div>
        <div class="col-md-8">
          <div class="card-body">
            <h5 class="card-title">Surface Light Field Fusion</h5>
            <p class="card-text author">Jeong Joon Park, Richard Newcombe, Steve Seitz<br><em>3DV 2018 (Oral)</em><br></p>
              <a href="https://arxiv.org/pdf/1809.02057.pdf" target="_blank"><button class="smallbtn"><i class="far fa-file-alt iconbtn"></i>Paper</button></a>
              <a href="https://grail.cs.washington.edu/projects/slfusion/" target="_blank"><button class="smallbtn"><i class="far fa-window-maximize iconbtn"></i>Website</button></a>
              <a href="https://youtu.be/CLQIkchy3Ak" target="new"><button class="smallbtn"><i class="fab fa-youtube iconbtn"></i>Video</button></a>
            </p>
              <br><br>
          </div>
        </div>
      </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>

  </body>
</html>
